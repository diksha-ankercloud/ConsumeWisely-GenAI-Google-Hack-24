{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import base64, httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image contains several bowls of fruit and yogurt. The fruit includes strawberries, blueberries, blackberries, kiwi, and orange slices.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import base64\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Path to the image file\n",
    "image_path = r\"C:\\Users\\DELL\\Downloads\\13-Google-GenAI-Hack-24\\GenAI-Google--Hack-24\\Frontend\\first.jpg\"\n",
    "\n",
    "# Read and convert the image to base64\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Create a message with the base64 encoded image\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"describe the fruit in this image\"},\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Invoke the model with the message\n",
    "response = model.invoke([message])\n",
    "\n",
    "# Print the model's response\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    system_instrcution = \"Do what the prompt says.\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = ''' \n",
    "i'm giving you a image bytestring. describe it to{refrence ipttt}\n",
    "\n",
    "\n",
    "''',\n",
    "    input_variables = [\"input_language\", \"output_language\", \"input\"]\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | llm\n",
    "op = chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\output_parsers\\__init__.py:38: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain.output_parsers.pandas_dataframe import PandasDataFrameOutputParser\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Describe the following image\"),\n",
    "    (\"human\", [\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"},\n",
    "        },\n",
    "    ]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    system = \"all your answers should be in hindi\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kuch toh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"describe what is not in the image\\n\"),\n",
    "    (\"human\", [\n",
    "        {    \n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"},\n",
    "        },\n",
    "    ]),\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "        SystemMessage(content='describe the image'),\n",
    "        HumanMessage(content=' print my age too, age is{age}'),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            [{'image_url': \"data:image/jpeg;base64,{image_data}\"}]\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The image shows a flat lay of a delicious and healthy breakfast spread on a marble countertop. There are four bowls of oatmeal topped with various fruits like strawberries, blueberries, blackberries, kiwi, and orange slices. Two plates hold freshly made waffles, also adorned with fruit and a drizzle of honey. A cup of coffee, a small pitcher of milk, a jar of honey with a honey dipper, a small bowl of red pepper flakes, and a vase of green viburnum flowers complete the arrangement. The scene evokes a sense of freshness and vibrancy, perfect for starting the day. \\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-38c8334e-3c84-4417-b69f-bcfd6e85ecbd-0', usage_metadata={'input_tokens': 273, 'output_tokens': 117, 'total_tokens': 390})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chat_prompt | model \n",
    "\n",
    "# Path to the image file\n",
    "image_path = r\"C:\\Users\\DELL\\Downloads\\13-Google-GenAI-Hack-24\\GenAI-Google--Hack-24\\Frontend\\first.jpg\"\n",
    "\n",
    "# Read and convert the image to base64\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"age\": \"20\",\n",
    "        \"image_data\": image_data\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = ''' \n",
    "i'm giving you a image bytestring. describe it to{refrence ipttt}\n",
    "\n",
    "\n",
    "''',\n",
    "    input_variables = [\"input_language\", \"output_language\", \"input\"]\n",
    ")\n",
    "\n",
    "\n",
    "chain = chat_prompt | llm\n",
    "op = chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='A flat lay photo of a delicious breakfast spread on a marble countertop. There are bowls of oatmeal and yogurt topped with fruit, plates with waffles, a cup of coffee, and various toppings. \\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-593b9d9a-63b8-40f1-8faf-6672d051fdaa-0', usage_metadata={'input_tokens': 272, 'output_tokens': 38, 'total_tokens': 310})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chat_prompt | model \n",
    "\n",
    "# Path to the image file\n",
    "image_path = r\"C:\\Users\\DELL\\Downloads\\13-Google-GenAI-Hack-24\\GenAI-Google--Hack-24\\Frontend\\first.jpg\"\n",
    "\n",
    "# Read and convert the image to base64\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"language\": \"English\",\n",
    "        \"image_data\": image_data\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "        SystemMessage(content='Describe the following image very briefly.'),\n",
    "        HumanMessage(content='Describe the following image.'),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            # This line is an ugly hack. It will trigger the ImagePromptTemplate internally (see [Line 455](https://github.com/langchain-ai/langchain/blob/d8a1f1114d839b2a902ff9bd4ae668751257414a/libs/core/langchain_core/prompts/chat.py#L455C1-L455C64))\n",
    "            [{'image_url': \"\"}]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "        HumanMessage(content='Describe the following image.'),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            [{'image_url': {'path': '{image_path}', 'detail': '{detail_parameter}'}}]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "url = 'https://fastly.picsum.photos/id/237/200/300.jpg?hmac=TmmQSbShHz9CdQm0NkEjx1Dyh_Y984R9LpNrpvH2D_U'\n",
    "\n",
    "detail = 'low'\n",
    "\n",
    "print(chat_prompt_template)\n",
    "# Output:\n",
    "# ChatPromptTemplate(input_variables=[], messages=[SystemMessage(content='Describe the following image very briefly.'), HumanMessagePromptTemplate(prompt=[ImagePromptTemplate(input_variables=[], template={'url': ''})])])\n",
    "\n",
    "result = chat_prompt_template.invoke(input={'url': url, 'detail': detail})\n",
    "print(result)\n",
    "# Output:\n",
    "# ChatPromptValue(messages=[SystemMessage(content='Describe the following image very briefly.'), HumanMessage(content=[{'type': 'image_url', 'image_url': {'url': 'https://fastly.picsum.photos/id/237/200/300.jpg?hmac=TmmQSbShHz9CdQm0NkEjx1Dyh_Y984R9LpNrpvH2D_U', 'detail': 'low'}}])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "image_path = 'path/to/image.png'\n",
    "detail_parameter = 'high'\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "        HumanMessage(content='Describe the following image.'),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            [{'image_url': {'path': '{image_path}', 'detail': '{detail_parameter}'}}]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = chat_prompt_template.format(image_path=image_path, detail_parameter=detail_parameter)\n",
    "\n",
    "print(prompt[:150])\n",
    "# Output:\n",
    "# Human: Describe the following image.\n",
    "# Human: [{'type': 'image_url', 'image_url': {'url': 'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABQAAABMXCAYAAAA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
